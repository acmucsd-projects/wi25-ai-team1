{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ── Configuration ───────────────────────────────────────────────\n",
    "base_url     = \"https://stats.ncaa.org\"\n",
    "output_dir   = \"statCSVs_2019_2023\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "years         = range(2019, 2024)\n",
    "stat_sequences = {\n",
    "    'Aces Per Set':       532,\n",
    "    'Assists Per Set':    522,\n",
    "    'Attacks Per Set':   1124,\n",
    "    'Blocks Per Set':     523,\n",
    "    'Digs Per Set':       524,\n",
    "    'Hitting Percentage': 520,\n",
    "    'Kills Per Set':      521,\n",
    "    'Points Per Set':     686,\n",
    "    'Triple Doubles':     929\n",
    "}\n",
    "\n",
    "# ── Helper: fetch & parse a table given a full href ──────────────\n",
    "def get_table(href):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"Referer\":     base_url + href\n",
    "    }\n",
    "    r = requests.get(base_url + href, headers=headers, timeout=10)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    tbl = soup.find(\"table\", id=\"rankings_table\")\n",
    "    if not tbl:\n",
    "        return None\n",
    "    cols = [th.get_text(strip=True) for th in tbl.find(\"thead\").find_all(\"th\")]\n",
    "    rows = []\n",
    "    for tr in tbl.find(\"tbody\").find_all(\"tr\"):\n",
    "        rows.append([td.get_text(strip=True) for td in tr.find_all(\"td\")])\n",
    "    return pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "# ── Step 1: Discover ranking_period for each year ────────────────\n",
    "period_by_year = {}\n",
    "for year in years:\n",
    "    print(f\"Finding ranking_period for {year}…\", end=\"\")\n",
    "    found = None\n",
    "    # try the first 100 period IDs\n",
    "    for p in range(1, 101):\n",
    "        href = (f\"/rankings/national_ranking?\"\n",
    "                f\"academic_year={year}.0&division=1.0&ranking_period={p}.0\"\n",
    "                f\"&sport_code=MVB&stat_seq=532.0\")\n",
    "        df = get_table(href)\n",
    "        if df is not None and not df.empty:\n",
    "            found = p\n",
    "            break\n",
    "    if found:\n",
    "        period_by_year[year] = found\n",
    "        print(f\"  ✔️  period = {found}\")\n",
    "    else:\n",
    "        print(\"  ⚠️  not found\")\n",
    "\n",
    "# ── Step 2: Scrape each stat for each year ────────────────────────\n",
    "for year, period in period_by_year.items():\n",
    "    print(f\"\\n--- Scraping stats for {year} (period={period}) ---\")\n",
    "    for stat_name, seq in stat_sequences.items():\n",
    "        href = (f\"/rankings/national_ranking?\"\n",
    "                f\"academic_year={year}.0&division=1.0&ranking_period={period}.0\"\n",
    "                f\"&sport_code=MVB&stat_seq={seq}.0\")\n",
    "        print(f\" • {stat_name}\", end=\"\")\n",
    "        df = get_table(href)\n",
    "        if df is None or df.empty:\n",
    "            print(\" — no data\")\n",
    "            continue\n",
    "        fname = f\"{stat_name.replace(' ', '_')}_Individual_{year}.csv\"\n",
    "        df.to_csv(os.path.join(output_dir, fname), index=False)\n",
    "        print(\" — saved\")\n",
    "\n",
    "print(\"\\nAll done! Check the folder:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f3c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ── Configuration ───────────────────────────────────────────────\n",
    "base_url     = \"https://stats.ncaa.org\"\n",
    "output_dir   = \"teamCSVs_2019_2023\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "years = range(2019, 2024)\n",
    "\n",
    "# Team stat_seq values\n",
    "team_stats = {\n",
    "    'Aces Per Set':               528,\n",
    "    'Assists Per Set':            527,\n",
    "    'Blocks Per Set':             529,\n",
    "    'Digs Per Set':               533,\n",
    "    'Hitting Percentage':         525,\n",
    "    'Kills Per Set':              526,\n",
    "    'Match W-L Pctg.':            530,\n",
    "    'Opponent Hitting Percentage':1140,\n",
    "    'Team Attacks Per Set':      1125\n",
    "}\n",
    "\n",
    "# ── Helper: fetch & parse a table given an href ────────────────\n",
    "def get_table(href):\n",
    "    r = requests.get(base_url + href, headers={\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"Referer\":     base_url + href\n",
    "    }, timeout=10)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    tbl = soup.find(\"table\", id=\"rankings_table\")\n",
    "    if not tbl:\n",
    "        return None\n",
    "    cols = [th.get_text(strip=True) for th in tbl.find(\"thead\").find_all(\"th\")]\n",
    "    rows = []\n",
    "    for tr in tbl.find(\"tbody\").find_all(\"tr\"):\n",
    "        rows.append([td.get_text(strip=True) for td in tr.find_all(\"td\")])\n",
    "    return pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "# ── Step 1: discover ranking_period for each year ───────────────\n",
    "period_by_year = {}\n",
    "for year in years:\n",
    "    for p in range(1, 101):\n",
    "        href = (\n",
    "            f\"/rankings/national_ranking?\"\n",
    "            f\"academic_year={year}.0&division=1.0&ranking_period={p}.0\"\n",
    "            f\"&sport_code=MVB&stat_seq=528.0\"  # try with Aces Per Set\n",
    "        )\n",
    "        df = get_table(href)\n",
    "        if df is not None and not df.empty:\n",
    "            period_by_year[year] = p\n",
    "            break\n",
    "\n",
    "# ── Step 2: scrape team stats only ──────────────────────────────\n",
    "for year, period in period_by_year.items():\n",
    "    print(f\"Scraping team stats for {year} (period={period}):\")\n",
    "    for name, seq in team_stats.items():\n",
    "        href = (\n",
    "            f\"/rankings/national_ranking?\"\n",
    "            f\"academic_year={year}.0&division=1.0&ranking_period={period}.0\"\n",
    "            f\"&sport_code=MVB&stat_seq={seq}.0\"\n",
    "        )\n",
    "        try:\n",
    "            df = get_table(href)\n",
    "            if df is not None and not df.empty:\n",
    "                fname = f\"{name.replace(' ', '_')}_Team_{year}.csv\"\n",
    "                df.to_csv(os.path.join(output_dir, fname), index=False)\n",
    "                print(f\"  ✔ {name}\")\n",
    "            else:\n",
    "                print(f\"  ⚠ {name} (no data)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ {name}: {e}\")\n",
    "\n",
    "print(\"Done. CSVs saved in\", output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
