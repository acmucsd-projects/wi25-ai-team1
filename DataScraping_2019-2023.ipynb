{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b55a20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping Individual stats for 2019...\n",
      "\n",
      "Scraping Team stats for 2019...\n",
      "\n",
      "Scraping Individual stats for 2020...\n",
      "\n",
      "Scraping Team stats for 2020...\n",
      "\n",
      "Scraping Individual stats for 2021...\n",
      "\n",
      "Scraping Team stats for 2021...\n",
      "\n",
      "Scraping Individual stats for 2022...\n",
      "\n",
      "Scraping Team stats for 2022...\n",
      "\n",
      "Scraping Individual stats for 2023...\n",
      "\n",
      "Scraping Team stats for 2023...\n",
      "\n",
      "Scraping match scores for 2019...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01: 100%|██████████| 27/27 [00:23<00:00,  1.13it/s]\n",
      "2019-02: 100%|██████████| 24/24 [00:20<00:00,  1.19it/s]\n",
      "2019-03: 100%|██████████| 26/26 [00:23<00:00,  1.13it/s]\n",
      "2019-04: 100%|██████████| 13/13 [00:11<00:00,  1.12it/s]\n",
      "2019-05: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n",
      "2019-12: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping match scores for 2020...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01: 100%|██████████| 27/27 [00:23<00:00,  1.14it/s]\n",
      "2020-02: 100%|██████████| 25/25 [00:22<00:00,  1.11it/s]\n",
      "2020-03: 100%|██████████| 28/28 [00:24<00:00,  1.14it/s]\n",
      "2020-04: 100%|██████████| 12/12 [00:10<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping match scores for 2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01: 100%|██████████| 10/10 [00:08<00:00,  1.15it/s]\n",
      "2021-02: 100%|██████████| 23/23 [00:20<00:00,  1.11it/s]\n",
      "2021-03: 100%|██████████| 28/28 [00:25<00:00,  1.11it/s]\n",
      "2021-04: 100%|██████████| 16/16 [00:15<00:00,  1.07it/s]\n",
      "2021-05: 100%|██████████| 4/4 [00:04<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping match scores for 2022...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01: 100%|██████████| 25/25 [00:26<00:00,  1.06s/it]\n",
      "2022-02: 100%|██████████| 25/25 [00:21<00:00,  1.17it/s]\n",
      "2022-03: 100%|██████████| 30/30 [00:26<00:00,  1.15it/s]\n",
      "2022-04: 100%|██████████| 19/19 [00:18<00:00,  1.03it/s]\n",
      "2022-05: 100%|██████████| 4/4 [00:03<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping match scores for 2023...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01: 100%|██████████| 26/26 [00:22<00:00,  1.15it/s]\n",
      "2023-02: 100%|██████████| 25/25 [00:21<00:00,  1.16it/s]\n",
      "2023-03: 100%|██████████| 30/30 [00:25<00:00,  1.20it/s]\n",
      "2023-04: 100%|██████████| 17/17 [00:25<00:00,  1.52s/it]\n",
      "2023-05: 100%|██████████| 3/3 [00:03<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup\n",
    "baseEndpoint = \"https://stats.ncaa.org\"\n",
    "output_stat_dir = \"statCSVs_2019_2023\"\n",
    "output_score_dir = \"scoreCSVs_2019_2023\"\n",
    "os.makedirs(output_stat_dir, exist_ok=True)\n",
    "os.makedirs(output_score_dir, exist_ok=True)\n",
    "years = range(2019, 2024)\n",
    "\n",
    "# ------------------- STATS SECTION ------------------- #\n",
    "def getStatDropdown(year, stat_type='I'):  # 'I' = Individual, 'T' = Team\n",
    "    example_url = f\"https://stats.ncaa.org/rankings/national_ranking?academic_year={year}.0&division=1.0&ranking_period=82.0&sport_code=MVB&stat_seq=532.0\"\n",
    "    response = requests.get(example_url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    dropdown_id = f\"stat_type_{stat_type}_N\"\n",
    "    dropdown_div = soup.find(\"div\", {\"aria-labelledby\": dropdown_id})\n",
    "    links = dropdown_div.find_all(\"a\") if dropdown_div else []\n",
    "\n",
    "    stat_names = [a.text.strip() for a in links if a.get(\"href\", \"\").startswith(\"/rankings\")]\n",
    "    stat_hrefs = [a[\"href\"] for a in links if a.get(\"href\", \"\").startswith(\"/rankings\")]\n",
    "\n",
    "    return stat_names, stat_hrefs\n",
    "\n",
    "def getTable(baseEndpoint, href):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"Referer\": f\"{baseEndpoint}{href}\"\n",
    "    }\n",
    "    response = requests.get(f\"{baseEndpoint}{href}\", headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    table = soup.find(\"table\", id=\"rankings_table\")\n",
    "    if not table:\n",
    "        return None\n",
    "\n",
    "    header_cells = table.find(\"thead\").find_all(\"th\")\n",
    "    headers = [th.get_text(strip=True) for th in header_cells]\n",
    "\n",
    "    data_rows = []\n",
    "    for tr in table.find(\"tbody\").find_all(\"tr\"):\n",
    "        row_data = []\n",
    "        for td in tr.find_all(\"td\"):\n",
    "            a = td.find(\"a\")\n",
    "            text = a.get_text(strip=True) if a else td.get_text(strip=True)\n",
    "            row_data.append(text)\n",
    "        data_rows.append(row_data)\n",
    "\n",
    "    return pd.DataFrame(data_rows, columns=headers)\n",
    "\n",
    "# Scrape stats for each year and type\n",
    "for year in years:\n",
    "    for stat_type, label in zip(['I', 'T'], ['Individual', 'Team']):\n",
    "        print(f\"\\nScraping {label} stats for {year}...\")\n",
    "        try:\n",
    "            stat_names, stat_hrefs = getStatDropdown(year, stat_type)\n",
    "            for name, href in zip(stat_names, stat_hrefs):\n",
    "                try:\n",
    "                    print(f\"  → {name}\")\n",
    "                    df = getTable(baseEndpoint, href)\n",
    "                    if df is not None:\n",
    "                        fname = f\"{name.replace(' ', '_')}_{label}_{year}.csv\"\n",
    "                        df.to_csv(os.path.join(output_stat_dir, fname), index=False)\n",
    "                except Exception as e:\n",
    "                    print(f\"    ❌ Failed to get {name}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to fetch dropdown for {label} {year}: {e}\")\n",
    "\n",
    "# ------------------- GAME SCORES SECTION ------------------- #\n",
    "for year in years:\n",
    "    yearly_dataframes = []\n",
    "    print(f\"\\nScraping match scores for {year}...\")\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        month_str = str(month).zfill(2)\n",
    "        url = f\"https://data.ncaa.com/casablanca/schedule/volleyball-men/d1/{year}/{month_str}/schedule-all-conf.json\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code != 200:\n",
    "                continue\n",
    "            game_dates = [x for x in response.json().get(\"gameDates\", []) if x.get(\"games\", 0) > 0]\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️ Skipping {url} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "        for date in tqdm(game_dates, desc=f\"{year}-{month_str}\"):\n",
    "            try:\n",
    "                month_, day_, year_ = date[\"contest_date\"].split(\"-\")\n",
    "                scoreboard_url = f\"https://www.ncaa.com/scoreboard/volleyball-men/d1/{year_}/{month_}/{day_}\"\n",
    "                resp = requests.get(scoreboard_url)\n",
    "                soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "                rows = []\n",
    "                for game in soup.find_all('ul', class_='gamePod-game-teams'):\n",
    "                    teams = game.find_all('li')\n",
    "                    if len(teams) == 2:\n",
    "                        team1 = teams[0].find('span', class_='gamePod-game-team-name').text.strip()\n",
    "                        score1 = teams[0].find('span', class_='gamePod-game-team-score').text.strip()\n",
    "                        team2 = teams[1].find('span', class_='gamePod-game-team-name').text.strip()\n",
    "                        score2 = teams[1].find('span', class_='gamePod-game-team-score').text.strip()\n",
    "                        rows.append([team1, score1, team2, score2, date[\"contest_date\"]])\n",
    "\n",
    "                if rows:\n",
    "                    df = pd.DataFrame(rows, columns=[\"Team 1\", \"Team 1 Score\", \"Team 2\", \"Team 2 Score\", \"Date\"])\n",
    "                    yearly_dataframes.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"    ❌ Error on {date['contest_date']}: {e}\")\n",
    "\n",
    "    # Save yearly results\n",
    "    if yearly_dataframes:\n",
    "        year_df = pd.concat(yearly_dataframes, ignore_index=True)\n",
    "        out_path = os.path.join(output_score_dir, f\"NCAA_Mens_VB_Scores_{year}.csv\")\n",
    "        year_df.to_csv(out_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
